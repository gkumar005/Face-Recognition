{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":679,"status":"ok","timestamp":1642302905537,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"},"user_tz":0},"id":"B9UqDsGQB11r"},"outputs":[],"source":["import numpy as np\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import torch\n","from torch.utils.data import Dataset\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","from torchvision.io import read_image\n","import pandas as pd\n","import cv2 \n","import torch.nn as nn\n","import glob\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import glob\n","from skimage import measure\n","from collections import Counter"]},{"cell_type":"markdown","source":["#Change file directory path here\n","All the results will be stored in cw_data directory"],"metadata":{"id":"LO7aW-vZBKqh"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","data_dir = \"/content/drive/MyDrive/Colab Notebooks/cs413/cw_data/DATA/\"\n","try:\n","  results_dir = \"/content/drive/MyDrive/Colab Notebooks/cs413/cw_data/results/\"\n","  os.mkdir(results_dir)\n","except:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QusTzJPRBOjv","executionInfo":{"status":"ok","timestamp":1642302926581,"user_tz":0,"elapsed":16821,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}},"outputId":"e33e3cc8-8725-4345-f8b8-4f2d225a5441"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":238,"status":"ok","timestamp":1642302941665,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"},"user_tz":0},"id":"aEVH0reuB75l"},"outputs":[],"source":["# Function to read and write frames\n","def read_frames(filename):\n","    video_cap = cv2.VideoCapture(filename)\n","\n","    count = 0\n","    frames = []\n","    while True:\n","        success, frame = video_cap.read()\n","\n","        if success:\n","            count += 1\n","            \n","            # convert from BGR to RGB format\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","            frames.append(frame)\n","        else:\n","            # print('Failed to read frame') # when last frame read\n","            break;\n","\n","\n","    print('Read ', count, ' frames in total')\n","    video_cap.release()\n","    \n","    return frames\n","\n","def write_frames(frames, filename, codec='H264'):\n","    \n","    print('Writing frames to ', filename)\n","    fourcc = cv2.VideoWriter_fourcc(*codec) # 'MP4V' or 'H264'\n","    writer = cv2.VideoWriter(filename, fourcc, 24, (frames[0].shape[1],frames[0].shape[0]), True)\n","\n","    for i in range(0,len(frames)):\n","\n","        frame = cv2.cvtColor(frames[i], cv2.COLOR_RGB2BGR)\n","\n","        writer.write(frame)\n","\n","    \n","    writer.release()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1642302943619,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"},"user_tz":0},"id":"YUUj0GYvcqwv"},"outputs":[],"source":["def bounding_box(comps, label=1): # return bounding box of a componenet\n","    \n","    # array of image coordinates in x and y\n","    xx, yy = np.meshgrid(np.arange(0,comps.shape[1]), np.arange(0,comps.shape[0]))\n","\n","    # mask/select by where value is given label (component)\n","    where_x = xx[comps==label]\n","    where_y = yy[comps==label]\n","    \n","    # find min and max extents of coordinates\n","    return np.min(where_x), np.min(where_y), np.max(where_x), np.max(where_y)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":249,"status":"ok","timestamp":1642304970534,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"},"user_tz":0},"id":"n1MUiSVR1I2j"},"outputs":[],"source":["# return labels and bounding boxes of all the cards in a frame using pretrained model\n","# rest is same as Image extracter test function in Task-2\n","def card_labelBB(comps,im_gray,im):\n","  unique = sorted([i[0] for i in Counter(list(comps.ravel())).most_common(20)])# unique labels \n","\n","  min_size = 20000\n","  thres_size = 500000\n","  max_size = 1500000\n","  bounding_boxes = []\n","  component_labels = [] # list of component images\n","\n","  for l in unique[1:]:\n","      bb = bounding_box(comps, label=l)\n","      # make a binary image for each component\n","      one_comp = np.zeros(im_gray.shape, dtype='uint8')\n","      one_comp[comps==l] = 1\n","\n","      # measure its size\n","      n = np.count_nonzero(one_comp)\n","\n","      # plot as image if it's big enough\n","      if (n>min_size) & (n< max_size):\n","          if n <= thres_size:\n","\n","            contours, hierarchy = cv2.findContours(one_comp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","            # filter noisy detection\n","            for c in contours:\n","              if cv2.contourArea(c) > 10000:\n","\n","                rect = cv2.minAreaRect(c)\n","\n","\n","                center, size, theta = rect\n","                box = cv2.boxPoints(rect)\n","                box = np.int0(box)\n","                width = int(rect[1][0])\n","                height = int(rect[1][1])\n","\n","                src_corners = box.astype(\"float32\")\n","\n","                dst_corners = np.array([[0, height-1],\n","                        [0, 0],\n","                        [width-1, 0],\n","                        [width-1, height-1]], dtype=\"float32\")\n","\n","                # the perspective transformation matrix\n","                M = cv2.getPerspectiveTransform(src_corners, dst_corners)\n","\n","                # directly warp the rotated rectangle to get the straightened rectangle\n","                warpped_card = cv2.warpPerspective(im, M, (width, height))\n","\n","                req_card = transform(warpped_card)\n","                req_card = req_card.unsqueeze(0)\n","                outputs = resnet(req_card)\n","                _, pred = torch.max(outputs.data, 1)\n","                \n","\n","                #bounding_boxes.append(bb)\n","                component_labels.append(pred) \n","                bounding_boxes.append(bb)\n","                #print('label ', l,'component size is ', n)\n","                \n","                # plt.imshow(card)\n","                # plt.show()\n","\n","  return component_labels,bounding_boxes"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":223,"status":"ok","timestamp":1642304976331,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"},"user_tz":0},"id":"aqngn-t1aSNK"},"outputs":[],"source":["# labels every 50th frame in the video using card_labelBB and return new sets of frames\n","def frame_labeller(frames):\n","  labelled_frames = []\n","\n","  for image in frames[0:len(frames)+1:50]:\n","\n","        im = np.asarray(image)\n","        im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n","\n","        # threshold at 248 given the distribution above\n","        threshed = np.zeros(im_gray.shape, 'int')\n","        threshed[(im[:,:,1] < 50) | (im[:,:,2] >= im[:,:,1]) | (im[:,:,0] >= im[:,:,1])] = 1\n","\n","        # creates componenets\n","        comps = measure.label(threshed, background=0)\n","\n","        labels,bndng_boxes = card_labelBB(comps,im_gray,im)\n","\n","        for i in range(len(labels)):\n","          bgr = (0, 255, 0) # color of the box\n","          x1 = bndng_boxes[i][0]\n","          y1 = bndng_boxes[i][1]\n","          x2 = bndng_boxes[i][2]\n","          y2 = bndng_boxes[i][3]\n","          label = labels[i].item()\n","          cv2.rectangle(im,(x1, y1), (x2, y2),(1, 1, 1), 3)\n","          label_font = cv2.FONT_HERSHEY_SIMPLEX\n","          cv2.putText(im, label_mapping[label], (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n","        labelled_frames.append(im)\n","          \n","        # plt.figure(figsize = (10,10))\n","        # plt.imshow(im)\n","        # plt.show()\n","  return labelled_frames\n"]},{"cell_type":"markdown","source":["Model and Label mapping Import"],"metadata":{"id":"w4R7RU33I2H1"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"XBEJ6OFnfq6R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642305049573,"user_tz":0,"elapsed":847,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}},"outputId":"76bb800e-830b-4b12-d87b-301d41c17996"},"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}],"source":["# trasnform the image to make prediction on the extracted cards from a frame\n","transform=transforms.Compose([transforms.ToPILImage(),\n","                                  #transforms.RandomResizedCrop(224), \n","                                  transforms.Resize((224,224)), \n","                                  transforms.ToTensor(),\n","                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","# Model Import\n","resnet = models.resnet50(pretrained=False)\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","in_features = resnet.fc.in_features\n","resnet.fc = nn.Linear(in_features, len(glob.glob( results_dir + \"train/*\")))\n","# importing pretrained model's state dictionary\n","resnet.load_state_dict(torch.load(f\"{results_dir}best_resnet50_lr01_sgd.pt\",map_location=torch.device('cpu')))\n","resnet.eval()\n","\n","# Import Label mapping\n","annot = [i.split(\"/\")[-1] for i in glob.glob(results_dir + \"train/*\")]\n","label_mapping = {i:idx for idx,i in enumerate(annot)}\n","label_mapping = dict((v,k) for k,v in label_mapping.items()) # label the original ids"]},{"cell_type":"markdown","source":["#Video Import and labelling"],"metadata":{"id":"M4utiYf7Kx9G"}},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58400,"status":"ok","timestamp":1642305129294,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"},"user_tz":0},"id":"bmNHZmkIJGgs","outputId":"37f5f5d5-6713-4ee9-d155-2376534ca97f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Read  215  frames in total\n","Read  522  frames in total\n"]}],"source":["# Importing the videos\n","frames1 = read_frames( data_dir + 'video-001.MOV')\n","frames2 = read_frames( data_dir + 'video-002.MOV')\n","# labelling the framse\n","# Takes around 5 mins to run\n","labelled_frames1 = frame_labeller(frames1)\n","labelled_frames2 = frame_labeller(frames2)"]},{"cell_type":"code","source":["# writing the video frames\n","# videos won't be seen on colab, you can download and run on your system to see the outputs.\n","# filename1 = 'lebld_vid-001.mp4'\n","# filename2 = 'lebld_vid-002.mp4'\n","# write_frames(labelled_frames1, results_dir + filename1, codec='MP4V') # use codec=MP4V on Google Colab\n","# write_frames(labelled_frames2, results_dir + filename2, codec='MP4V') # use codec=MP4V on Google Colab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2n6D0ZvCQuJT","executionInfo":{"status":"ok","timestamp":1642304230377,"user_tz":0,"elapsed":10963,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}},"outputId":"9b4253f8-edaf-4f1e-cf5f-1dd6da1cf465"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing frames to  /content/drive/MyDrive/Colab Notebooks/cs413/cw_data/results/lebld_vid-001.mp4\n","Writing frames to  /content/drive/MyDrive/Colab Notebooks/cs413/cw_data/results/lebld_vid-002.mp4\n"]}]},{"cell_type":"code","source":["for i in labelled_frames2:\n","  plt.figure(figsize = (10,10))\n","  plt.imshow(i)\n","  plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"18xHHTkuPWLi1XhCPOvQF69RL4H_PxaIt"},"id":"eBEpDXVXLJUK","executionInfo":{"status":"ok","timestamp":1642314745997,"user_tz":0,"elapsed":6805,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}},"outputId":"cda26a81-a235-4ca9-b092-a0b818643fb8"},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["  "],"metadata":{"id":"q0sEV1K6G4ZT"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"task-4.ipynb","provenance":[],"authorship_tag":"ABX9TyNwJGQpG0beKpvycnEuV4kR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}