{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"task-2.ipynb","provenance":[],"authorship_tag":"ABX9TyO1te2c/Rjdj0vYjemWI6Rc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"sCmIk7FJ7Mvw","executionInfo":{"status":"ok","timestamp":1642278800289,"user_tz":0,"elapsed":546,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}}},"outputs":[],"source":["from PIL import Image  # this contain the image class and methods from PIL library\n","import numpy as np # this imports the numerical and array library \n","import cv2\n","import matplotlib.pyplot as plt\n","from skimage import measure\n","import math\n","import scipy\n","import os\n","import sklearn\n","import glob\n","from collections import Counter\n"]},{"cell_type":"markdown","source":["# Important Note\n","(If running on Colab)\n","\n","*   Uncomment and run the pip install commands, as sift is compatible with older versions of openCV\n","*   You might have to restart the runtime and comment these commands to further run the code\n","\n"],"metadata":{"id":"gP8z6KqNmYgQ"}},{"cell_type":"code","source":["# !pip install opencv-python==3.4.0.14\n","# !pip install opencv-contrib-python==3.4.2.17"],"metadata":{"id":"pLFzQ1zVmXeF","executionInfo":{"status":"ok","timestamp":1642278822223,"user_tz":0,"elapsed":225,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Change file directory path here\n","All the results will be stored in cw_data directory."],"metadata":{"id":"AG0wzLrVk15v"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","data_dir = \"/content/drive/MyDrive/Colab Notebooks/cs413/cw_data/DATA/\"\n","try:\n","  results_dir = \"/content/drive/MyDrive/Colab Notebooks/cs413/cw_data/results/\"\n","  os.mkdir(results_dir)\n","except:\n","  pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i5aW0GuT7RNa","executionInfo":{"status":"ok","timestamp":1642278825468,"user_tz":0,"elapsed":1755,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}},"outputId":"15b50e79-8a05-4ce2-c10d-b47b455e89ac"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["def bounding_box(comps, label=1): # returns bounding boxes of a component in an image\n","    \n","    # array of image coordinates in x and y\n","    xx, yy = np.meshgrid(np.arange(0,comps.shape[1]), np.arange(0,comps.shape[0]))\n","\n","    # mask/select by where value is given label (component)\n","    where_x = xx[comps==label]\n","    where_y = yy[comps==label]\n","    \n","    # find min and max extents of coordinates\n","    return np.min(where_x), np.min(where_y), np.max(where_x), np.max(where_y)"],"metadata":{"id":"Liv_6oKs7TxJ","executionInfo":{"status":"ok","timestamp":1642278831850,"user_tz":0,"elapsed":258,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Same function as Task-1\n","# Returns a list of all the cards in a training image\n","\n","def image_extracter(comps,im_gray,im):\n","\n","  unique = sorted([i[0] for i in Counter(list(comps.ravel())).most_common(25)])# unique labels \n","\n","  min_size = 100000 # minimum pixel size threshold\n","  thres_size = 500000 # Average max pixel size of a card\n","  max_size = 1500000 # Max Average pixel size of any component.\n","  bounding_boxes = []\n","  component_images = [] # list of component images\n","\n","  for l in unique[1:]: # we know label 0 is always the entire image, so, sliced the list from 1.\n","      bb = bounding_box(comps, label=l)\n","      # make a binary image for each component\n","      one_comp = np.zeros(im.shape[0:2], dtype='uint8')\n","      one_comp[comps==l] = 1\n","\n","\n","      # measure its size\n","      n = np.count_nonzero(one_comp)\n","      # plot as image if it's big enough\n","      if (n>min_size) & (n< max_size):\n","          card_image = []\n","          if n <= thres_size:\n","\n","            req_card = im[bb[1]:bb[3],bb[0]:bb[2]]\n","\n","            #bounding_boxes.append(bb)\n","            card_image.append(req_card)\n","            component_images += card_image \n","            print('label ', l,'component size is ', n)\n","            \n","            plt.imshow(cv2.cvtColor(req_card, cv2.COLOR_BGR2RGB))\n","            plt.show()\n","          # Further breaks the components which were left with more than one cards attached, by reducing the threshold further (from 248 to 205)\n","          # thres_size is used to locate such components which has more than one cards combined.\n","          else: \n","            im_mrthan1 = im_gray[bb[1]:bb[3],bb[0]:bb[2]] \n","            img_mrthan1c = im[bb[1]:bb[3],bb[0]:bb[2]]\n","            threshed_mr1 = np.zeros(im_mrthan1.shape, 'int')\n","            threshed_mr1[(im_mrthan1<205)] = 1\n","            comp_mrt1 = measure.label(threshed_mr1,background=0)\n","            component_images += image_extracter(comp_mrt1,im_mrthan1,img_mrthan1c) # uses recursion to extracts the cards from those comps.\n","\n","  return component_images"],"metadata":{"id":"sKJmpOwtEVIB","executionInfo":{"status":"ok","timestamp":1642278833336,"user_tz":0,"elapsed":240,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Train-001 cards extract"],"metadata":{"id":"JLwlCMGelrOF"}},{"cell_type":"code","source":["# Importing train-001 image\n","im = cv2.imread(data_dir + 'train-0'+ str(1).zfill(2) +'.jpg')\n","\n","im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n","fig = plt.figure(figsize=(10,10))\n","plt.imshow(im_gray, 'gray')\n","plt.show()\n","\n","# threshold at 248 given the distribution above \n","# All the training images has more or less similar distribution, so used the same as task-1\n","threshed = np.zeros(im_gray.shape, 'int')\n","threshed[(im_gray<248)] = 1\n","\n","# creates componenets\n","comps = measure.label(threshed, background=0)\n","#plt.imshow(comps)\n","\n","train_noId_cards = image_extracter(comps,im_gray,im)"],"metadata":{"id":"_zcJ2R8h7btY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# importing all the training images and their Ids for NN match\n","train_images = []\n","train_ids = []\n","for folder in glob.glob( results_dir + f\"train/*\"):\n","  label = folder.split(\"/\")[-1]\n","  for img in glob.glob(f\"{folder}/*\"):\n","    #if str(img).find(\"aug\") < 0:\n","    image = cv2.imread(img)\n","    train_images.append(image)\n","    train_ids.append(label)\n","    print(img)\n","                  "],"metadata":{"id":"_yShkA5K6a5x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Nearest Neighbour Match SIFT\n","Used Lowe's keypoints and a metric derived from it to score the closeness between the images.\n","\n","Score = (total lowe kp matched between descriptors)/(total key points).\n","\n","Also returns known images (based on a score threshold) which I call validation set for now.\n","\n","Bear with it as it might takes 15-20 min to extract the matches for all the images"],"metadata":{"id":"j7k0O1RHoxXB"}},{"cell_type":"code","source":["# returns closest labels, images and scores\n","def NN(img,train_images,M,Ids):\n","\n","  kp1, des1 = sift.detectAndCompute(img,None)\n","\n","  perc_similarity = []\n","\n","  for img2 in train_images:\n","    kp2, des2 = sift.detectAndCompute(img2,None)\n","\n","    matches = flann.knnMatch(des1,des2,k=2) # find matches!\n","    lowe_kp = 0\n","    for m,n in matches:\n","      if m.distance < 0.7*n.distance:\n","        lowe_kp += 1\n","    perc_similarity.append(lowe_kp/len(kp1)) # Score\n","\n","  indices = np.argsort(-1*np.array(perc_similarity)) # Unlike distances it has to be sorted in descending order.\n","  closest_images = [train_images[k] for k in indices]\n","  closest_perc = [perc_similarity[k] for k in indices]\n","  labl = [Ids[k] for k in indices]\n","  return closest_images[:M],closest_perc[:M],labl[:M]\n"],"metadata":{"id":"SvX3NfF29MFO","executionInfo":{"status":"ok","timestamp":1642279217124,"user_tz":0,"elapsed":232,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Uses above written NN function to fetch all the NN images and their labels and score from the training sets and plot them\n","# Also returns all the known images based on the threshold observed from the data\n","def match_finder(cards,train_images,train_ids,no_NN):\n","\n","  known_im = []\n","  known_im_ids = []\n","  tot_cards = len(cards)\n","\n","  for im in cards:\n","    closest_images,closest_sim_perc,label = NN(im,train_images,no_NN,train_ids)\n","\n","    if closest_sim_perc[0] > 0.2: # threshold...\n","    #if first image has threshold > 0.2, called it known image(its present in training data(002-014) as well), validated manually.\n","      known_im.append(im)\n","      known_im_ids.append(label[0])\n","    print(\"image\")\n","    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n","    plt.show()\n","    print(\"matches\")\n","    # display closest images and their distances\n","    fig = plt.figure(figsize=(20,50))\n","    for j in range(no_NN):\n","      plt.subplot(tot_cards,no_NN,j+1)\n","      plt.imshow(cv2.cvtColor(closest_images[j], cv2.COLOR_BGR2RGB))\n","      plt.axis('off')\n","      plt.title(str(round(closest_sim_perc[j],4)))\n","      plt.subplots_adjust(wspace=None, hspace=None)\n","        \n","    plt.show()\n","  return known_im,known_im_ids "],"metadata":{"id":"JhcR5Rg8FT5e","executionInfo":{"status":"ok","timestamp":1642282896638,"user_tz":0,"elapsed":256,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["sift = cv2.xfeatures2d.SIFT_create()\n","FLANN_INDEX_KDTREE = 1\n","val_im = []\n","val_ids = []\n","index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n","search_params = dict(checks=50)   # or pass empty dictionary\n","flann = cv2.FlannBasedMatcher(index_params,search_params) # make FLANN searcher\n","no_NN = 3 # number of nearest neighbors \n","known_valc,known_valc_ids = match_finder(train_noId_cards,train_images,train_ids,no_NN)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1CJ94jb1QzXZUjhrdh8TL_bE-g5IvvRG3"},"id":"__rHGMHwje8z","executionInfo":{"status":"ok","timestamp":1642284188277,"user_tz":0,"elapsed":1290519,"user":{"displayName":"Gaurav Kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04629247398058989618"}},"outputId":"92b4bfdd-3690-4763-cadb-c7d12e733da2"},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# creating the val directory\n","try:\n","  os.mkdir(results_dir + \"val/\")\n","except:\n","  pass "],"metadata":{"id":"SUNwvtV57ICF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving all the known images in the same format as training dataset\n","for i in range(len(known_valc_ids)): \n","  try:\n","    os.mkdir(results_dir + f'val/{known_valc_ids[i]}')\n","  except:\n","    pass\n","  cv2.imwrite( results_dir + f'val/{known_valc_ids[i]}/img_val_{i}.jpg',known_valc[i])"],"metadata":{"id":"2yU8QzkGTyUK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Test data preparation\n","Image Extracter test: extracts images by using persecpetive tronsform and the minimum area rectangle contours of a component.\\\n","Finds source and destination cordinates using bounding reactangle with minimum area.\\\n","** Minimum area rectangle was easy locate on contours of the components.\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"PgkKf4sfK4qu"}},{"cell_type":"code","source":["def image_extracter_test(comps,im_gray,im):\n","  unique = sorted([i[0] for i in Counter(list(comps.ravel())).most_common(20)])# unique labels \n","\n","  min_size = 100000 # minimum pixel size threshold\n","  thres_size = 500000 # Average max pixel size of a card\n","  max_size = 1500000 # Max Average pixel size of any component.\n","  bounding_boxes = []\n","  component_images = [] # list of component images\n","\n","  for l in unique[1:]:\n","      bb = bounding_box(comps, label=l)\n","      # make a binary image for each component\n","      one_comp = np.zeros(im_gray.shape, dtype='uint8')\n","      one_comp[comps==l] = 1\n","\n","\n","      # measure its size\n","      n = np.count_nonzero(one_comp)\n","\n","      # plot as image if it's big enough\n","      if (n>min_size) & (n< max_size):\n","          card_image = []\n","          if n <= thres_size:\n","            # find contours of a component\n","            contours, hierarchy = cv2.findContours(one_comp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n","            # filter noisy detection\n","            for c in contours:\n","              if cv2.contourArea(c) > 10000: # exclude noises from the contours\n","\n","                rect = cv2.minAreaRect(c) # finds minimum area rectangle parameters\n","\n","\n","                center, size, theta = rect\n","                box = cv2.boxPoints(rect)\n","                box = np.int0(box)\n","                width = int(rect[1][0])\n","                height = int(rect[1][1])\n","                # utillising rectangle's corners and width and height to get source and destination corners \n","                src_corners = box.astype(\"float32\")\n","\n","                dst_corners = np.array([[0, height-1],\n","                        [0, 0],\n","                        [width-1, 0],\n","                        [width-1, height-1]], dtype=\"float32\")\n","\n","                # the perspective transformation matrix\n","                M = cv2.getPerspectiveTransform(src_corners, dst_corners)\n","\n","                # warps the image component\n","                warpped_card = cv2.warpPerspective(im, M, (width, height))\n","                if height > width:\n","                  req_card = scipy.ndimage.rotate(warpped_card, 0, reshape=True)\n","                else:\n","                  req_card = scipy.ndimage.rotate(warpped_card, 90, reshape=True)\n","\n","                #bounding_boxes.append(bb)\n","                card_image.append(cv2.cvtColor(req_card, cv2.COLOR_RGB2BGR))\n","                component_images += card_image \n","                print('label ', l,'component size is ', n)\n","                \n","                plt.imshow(req_card)\n","                plt.show()\n","          else: # recursively extract cards out of components with more than one card\n","            im_mrthan1 = im_gray[bb[1]:bb[3],bb[0]:bb[2]]\n","            img_mrthan1 = im[bb[1]:bb[3],bb[0]:bb[2]]\n","            threshed_mr1 = np.zeros(im_mrthan1.shape, 'int')\n","            threshed_mr1[(im_mrthan1<205)] = 1\n","            comp_mrt1 = measure.label(threshed_mr1,background=0)\n","            component_images += image_extracter(comp_mrt1,im_mrthan1,img_mrthan1)\n","\n","  return component_images"],"metadata":{"id":"Fh8crdCa7Xbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creates a dictionary with key as test image name and values as list of cards in it.\n","# Takes around 3-4 minutes to get all the cards\n","test_images = {}\n","\n","for folder in glob.glob( data_dir + \"*\"):\n","    if str(folder).find(\"test\") >= 0:\n","      \n","      image = Image.open(folder)\n","      im = np.asarray(image)\n","\n","      im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n","      fig = plt.figure(figsize=(10,10))\n","      plt.imshow(im_gray, 'gray')\n","      plt.show()\n","\n","      # masks the green background\n","      threshed = np.zeros(im_gray.shape, 'int')\n","      threshed[(im[:,:,1] < 50) | (im[:,:,2] >= im[:,:,1]) | (im[:,:,0] >= im[:,:,1])] = 1\n","\n","      # creates componenets\n","      comps = measure.label(threshed, background=0)\n","      plt.imshow(threshed)\n","      plt.show\n","\n","      test_cards = image_extracter_test(comps,im_gray,im)\n","      test_images[folder.split(\"/\")[-1].split(\".\")[0]] = test_cards\n","      #known_testc,known_testc_ids = match_finder(test_cards,train_images,train_ids,no_NN)"],"metadata":{"id":"soLqVtzd-jBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# manually labelled the test datasets with a dictionary (image names : ids)\n","# Unknown cards are labelled as \"000\"\n","test_labels = {\"test-001\": \"000,044,114,109,189,056,138,147,000,154,189,139\".split(\",\"),\n","\"test-007\": \"139,181,138,000,000,134,189,189,147,154,000,000,044,109,056,138\".split(\",\"),\n","\"test-010\": \"109,000,151,134,168,000,168,000,138,154\".split(\",\"),\n","\"test-006\": \"076,172,037,000,001,000,044,114,189,109,138,056,147,000,138\".split(\",\"),\n","\"test-009\": \"181,139,000,134,000,189,154,147,168,000,056,138,044,109\".split(\",\"),\n","\"test-005\": \"001,172,056,109,154,076,044,189,147,000,063,000,189,139,037\".split(\",\"),\n","\"test-004\": \"134,138,000,000,015,154,056,189,114,147,109\".split(\",\"),\n","\"test-003\": \"000,134,000,181,168,189,000,154,147,138,056,109\".split(\",\"),\n","\"test-002\": \"189,000,000,139,044,147,181,109,001,189\".split(\",\")}"],"metadata":{"id":"V20qng7GGoeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","  unique_labels = set([j for i in test_labels.values() for j in i])\n","  os.mkdir(results_dir + 'test/')\n","  for cat in unique_labels:\n","    os.mkdir(results_dir + f'test/{cat}/')\n","except:\n","  pass"],"metadata":{"id":"xJ3NKToQGikL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_files = [] # list of all test image names\n","for folder in glob.glob( data_dir + f\"*\" ):\n","  if str(folder).find(\"test\") >= 0:\n","    test_files.append(folder.split(\"/\")[-1].split(\".\")[0])"],"metadata":{"id":"eiC2hftqMJVt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving the test cards in the same fashion as train and val\n","\n","for i in test_files:\n","#os.mkdir(\"content/drive/MyDrive/Colab Notebooks/cs413/cw_data/test/\") \n","  testcards = test_images[i]\n","  label_i = test_labels[i]\n","  \n","  for j in range(len(testcards)):\n","      # print(label_i[j])\n","      # plt.imshow(testcards[j])\n","      # plt.show()\n","      cv2.imwrite( results_dir + f'test/{label_i[j]}/img_{i}_{j}.jpg',testcards[j])"],"metadata":{"id":"JUgtJCC4U0Zg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"O59QVMGD4JMX"},"execution_count":null,"outputs":[]}]}